import gradio as gr
import cv2
import numpy as np
import tensorflow as tf
from ultralytics import YOLO
from PIL import Image
import os


yolo_model_path = "/kaggle/input/modelchinh/other/default/1/model23.pt"
keras_model_path = "/kaggle/input/modelchinh/other/default/1/model9.h5"
output_dir = "detected_foods"


yolo_model = YOLO(yolo_model_path)
keras_model = tf.keras.models.load_model(keras_model_path)
input_shape = keras_model.input_shape[1:3]


class_names = [
    'cahukho', 'canhcai', 'canhchua', 'com trang', 'dauhusotca',
    'gachien', 'raumuongxao', 'thitkho', 'thitkhotrung', 'trungchien'
]

food_prices = {
    'cahukho': 20000,
    'canhcai': 10000,
    'canhchua': 10000,
    'com trang': 5000,
    'dauhusotca': 20000,
    'gachien': 20000,
    'raumuongxao': 10000,
    'thitkho': 20000,
    'thitkhotrung': 20000,
    'trungchien': 5000
}


os.makedirs(output_dir, exist_ok=True)
food_history = []


def classify_image(image):
    results = yolo_model(image)
    detections = results[0].boxes.data.cpu().numpy()
    predicted_foods = []
    total_price = 0
    cropped_images = []

    for i, det in enumerate(detections):
        x1, y1, x2, y2, confidence, class_id = det
        class_id = int(class_id)

        if confidence < 0.2:
            continue

        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
        crop = image[y1:y2, x1:x2]

        if crop.size == 0:
            continue

        food_filename = os.path.join(output_dir, f"food_{i}.jpg")
        cv2.imwrite(food_filename, cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))

        resized = cv2.resize(crop, input_shape)
        input_data = np.expand_dims(resized.astype(np.float32) / 255.0, axis=0)
        predictions = keras_model.predict(input_data)
        predicted_index = np.argmax(predictions)
        predicted_food = class_names[predicted_index]

        predicted_foods.append(predicted_food)
        total_price += food_prices.get(predicted_food, 0)
        cropped_images.append(Image.fromarray(crop))

    if not predicted_foods:
        return "KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c mÃ³n Äƒn nÃ o.", "0Ä‘", "\n".join(food_history), []

    result_text = "\n".join([f"{food}: {food_prices.get(food, 'KhÃ´ng rÃµ giÃ¡'):,}Ä‘" for food in predicted_foods])
    total_price_text = f"{total_price:,}Ä‘"

    food_history.append(f"{result_text} â†’ Tá»•ng: {total_price_text}")
    history_text = "\n\n".join(food_history)

    return result_text, total_price_text, history_text, cropped_images


with gr.Blocks(title="Nháº­n diá»‡n MÃ³n Ä‚n Canteen UEH", theme=gr.themes.Soft()) as demo:
    gr.Markdown("<h1 style='text-align: center;'>ğŸœ Nháº­n diá»‡n MÃ³n Ä‚n Canteen UEH (AI Challenges 3ITECH 2025)</h1>")
    gr.Markdown(f"<h3 style='text-align: center;'>CÃ¡c mÃ³n Äƒn nháº­n diá»‡n: {', '.join(class_names)}</h3>")

    with gr.Row():
        with gr.Column():
            gr.Markdown("ğŸ“¸ Táº£i lÃªn áº£nh mÃ¢m cÆ¡m:")
            image_input = gr.Image(type="numpy", label="áº¢nh mÃ¢m cÆ¡m", interactive=True)
            nhan_dien_button = gr.Button("ğŸ” Nháº­n diá»‡n vÃ  TÃ­nh tiá»n", variant="primary")
            reload_button = gr.Button("ğŸ”„ Táº£i láº¡i", variant="secondary")

            gr.Markdown("ğŸ–¼ï¸ MÃ³n Äƒn Ä‘Ã£ cáº¯t:")
            gallery_output = gr.Gallery(label="áº¢nh mÃ³n Äƒn", show_label=True, columns=3, height="auto")

        with gr.Column():
            gr.Markdown("ğŸŒ¼ Káº¿t quáº£ nháº­n diá»‡n:")
            food_output = gr.Textbox(label="CÃ¡c mÃ³n Äƒn:", lines=5)
            total_output = gr.Textbox(label="Tá»•ng tiá»n:", lines=1)
            gr.Markdown("ğŸ“œ Lá»‹ch sá»­ nháº­n diá»‡n:")
            history_output = gr.Textbox(label="Lá»‹ch sá»­ mÃ³n Äƒn:", lines=10, interactive=False)

    nhan_dien_button.click(
        fn=classify_image,
        inputs=image_input,
        outputs=[food_output, total_output, history_output, gallery_output]
    )

    reload_button.click(
        fn=lambda: (None, "", "", "", []),
        outputs=[image_input, food_output, total_output, history_output, gallery_output]
    )

demo.launch(debug=True, share=True)
