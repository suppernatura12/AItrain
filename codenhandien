
import gradio as gr
import cv2
import numpy as np
import tensorflow as tf
from ultralytics import YOLO
from PIL import Image
import os


file_model_path = "/content/drive/MyDrive/nhandienCNN.tflite" 



yolo_model = YOLO("yolov8n.pt")


interpreter = tf.lite.Interpreter(model_path=file_model_path)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
input_shape = input_details[0]['shape']


class_names = [
    "Ca hu kho", "Canh cai", "Canh chua", "Com trang", "Dau hu sot ca",
    "Ga chien", "Rau muong xao", "Thit kho", "Thit kho trung", "Trung chien"
]

food_prices = {
    "Ca hu kho": 20000,
    "Canh cai": 10000,
    "Canh chua": 10000,
    "Com trang": 5000,
    "Dau hu sot ca": 20000,
    "Ga chien": 20000,
    "Rau muong xao": 10000,
    "Thit kho": 20000,
    "Thit kho trung": 20000,
    "Trung chien": 5000
}

def classify_image(image):
    results = yolo_model(image)
    detections = results[0].boxes.data.cpu().numpy()
    predicted_foods = []
    total_price = 0
    for det in detections:
        x1, y1, x2, y2, confidence, class_id = det
        class_id = int(class_id)

        if confidence < 0.3:
            continue

        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
        crop = image[y1:y2, x1:x2]
        if crop.size == 0:
            continue

        resized = cv2.resize(crop, (input_shape[1], input_shape[2]))
        input_data = np.expand_dims(resized.astype(np.float32) / 255.0, axis=0)

        interpreter.set_tensor(input_details[0]['index'], input_data)
        interpreter.invoke()
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_index = np.argmax(output_data)
        predicted_food = class_names[predicted_index]

        predicted_foods.append(predicted_food)
        total_price += food_prices.get(predicted_food, 0)

    if not predicted_foods:
        return "KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c mÃ³n Äƒn", "0Ä‘"

    result_text = "\n".join([f"{food}: {food_prices[food]:,}Ä‘" for food in predicted_foods])
    total_price_text = f"{total_price:,}Ä‘"
    return result_text, total_price_text

with gr.Blocks(title="Nháº­n diá»‡n MÃ³n Ä‚n Canteen UEH", theme=gr.themes.Soft()) as demo:
    gr.Markdown("<h1 style='text-align: center;'>ğŸœ Nháº­n diá»‡n MÃ³n Ä‚n Canteen UEH (AI Challenges 3ITECH 2025)</h1>")
    gr.Markdown(f"<h3 style='text-align: center;'>CÃ¡c mÃ³n Äƒn: {', '.join(class_names)}</h3>")

    with gr.Row():
        with gr.Column():
            gr.Markdown("ğŸ“¸ Táº£i lÃªn áº£nh mÃ¢m cÆ¡m:")
            image_input = gr.Image(type="numpy", label="áº¢nh mÃ¢m cÆ¡m", interactive=True)
            nhan_dien_button = gr.Button("ğŸ” Nháº­n diá»‡n vÃ  TÃ­nh tiá»n", variant="primary")
            reload_button = gr.Button("ğŸ”„ Táº£i láº¡i", variant="secondary")

        with gr.Column():
            gr.Markdown("ğŸŒ¼ Káº¿t quáº£ nháº­n diá»‡n:")
            food_output = gr.Textbox(label="CÃ¡c mÃ³n Äƒn Ä‘Ã£ phÃ¡t hiá»‡n", lines=5)
            total_output = gr.Textbox(label="Tá»•ng tiá»n", lines=1)

    nhan_dien_button.click(fn=classify_image, inputs=image_input, outputs=[food_output, total_output])
    reload_button.click(fn=lambda: (None, "", ""), outputs=[
        image_input, food_output, total_output
    ])

demo.launch(debug=True, share=True)
